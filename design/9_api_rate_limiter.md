# Api Rate Limiter
## What is a rate limiter
* service receives a lot of requests
* can only serve a limited amount of requests
* to handle this, we need throttling or rate limiting
  * restrict amount of incoming requests, so our service can respond to them all
* limits number of events an entitty can perform in a particular time window
  * user can only send one message per second
  * user is allowed only 3 failed credit card transactions per day
  * single ip can only create 20 accounts per day
* caps requests to an amt, blocks the rest

## Why do we need Api rate limiting?
* prevents denial of service attacks DOS
* prevents brute force password attempts
  * brute force credit card transactions
* usually attacks are a barrage of HTTP requests which look real but are generated by machine or bots
* hard to detect, can easily bring down service, app, or API
* prevents revenue loss, reduces infra costs, stop spam, stop online harrassment
* Scenarios where rate limiting is good
  * misbehaving clients / scripts
  * security
  * prevent abusive behavior and bad design practices
  * keep costs and resource usage under control
  * revenue
    * pay for higher rates
  * eliminate spikiness in traffic


## requirements and goals of the system
### functional
* limit the number of requests an entity can send to an api within a time window, e.g. 15 requests per second
* the apis are accessible through a cluster, so the rate limit should be considered across different servers.
  * the user should get an error message whenever the threshold is crossed within a single server or across a combination of servers

### non functional
* The system should be highly available. rate limiter needs to be up to protect our service
* rate limiter should not add a lot of lag

## How to do rate limiting
* Rate limiting
  * process to define rate and speed at which consumers can access apis
* throttling
  * process of controlling the usage of the apis by customers during a given period
  * can be defined at application level or api level
  * when limit is crossed, server returns HTTP 429 "Too many requests" to client

## Different types of throttling
3 types
* hard throttling
  * api requests cannot exceed the throttle limit
* soft throttling
  * set api request limit to exceed a certain percentage
    * limit is 100, with 10% exceed limit
      * rate limiter allows up to 110 requests per period
* elastic or dynamic throttling
  * number of requests can exceed throttle limit if resources are available
  * ex: user has 100 messages / min throttle limit
    * we can allow >100 requests / min if resources are available

## different algorithms for rate limiting
* Rate limiting algorithms
  * Fixed Window Algorithm
    *  time window is considered from start of time unit to end of time unit
    *  if our window is 2 seconds, and we allow one request per two seconds
       * in this example, window 0 is from start of second 0 to end of second 1
       * w1 = [s2, s3], w2 = [s4, s5]
       * say we do r1 in second 0, then r2 and r3 in second 2
         * only r3 is throttled
  * Rolling Window Algorithm
    *  window is considered from the fraction of the time at which the request is made plus the time window length
    *  ex: window len = 1s, m1 at 0.3 s, m2 at 0.4 s
       * here the window is [s0.3, s1.3]

## high level design for rate limiter
* rate limiter decides which request will be served by the API servers and which will be declined
* when new requests comes in, server asks rate limiter to decide to serve or throttle

## Basic System Design and Algorithm
* can use a hash table
* key user_id, value = tuple(request_count, window_start_time)
* request comes in
  * if user_id not in table
    * table[user_id] = (1, timestamp)
  * if user_id in table
    * if current_time - start_time > 1 min
      * table[user_id] = 1, timestamp
    * else
      * if count >= threshold
        * reject requests
      * else increment count

* issues:
  * race condition
    * if two requests come in to increment the count concurrently, we can have a lower count than expected
    * can use locks on the counters
    * redis lock, memcached lock, implement lock ourselves on hash table
  * fixed window algorithm
    * if 3 requests come in at the end of the window, then 3 requests come in at the start of the next window
      * we technically had 6 requests in a time period less than the window
    * need to use sliding window in this case
* memory to store all of the user data
  * assume hash table solution
    * user_id takes 8 bytes, 2 byte count
    * lets say the timestamp takes 2 bits ( we only store the minute part)
    * 12 bytes per user
    * assume the hash table has 20 bytes of overhead per record
    * (12 + 20) bytes * 1 million = 32 MB
    * if we assume we need a 4 byte number to lock each user's record to solve our atomicity problems
      * need 36MB memory
    * This can easily fit on one server
    * We do not want to route all traffic to single machine
    * Assuming a rate limit of 10 requests per second, this would translate into 10 million requests / second
    * too much for single server
    * practically we can assume we would use Redis or Memcached type solution in a distributed setup
    * store all data in the remote Redis servers, rate limiter servers read and update these servers before serving or throttling requests

## Sliding Window Algorithm
* Need to track each request per user
* store the timestamp of each request in a redis sorted set in our value field of hash table
* user_id key, value: sorted_set(timestamps)
* assume limit of 3 requests / min
* rate limiter steps
    * remove all timestamps from sorted set less than current_time - 1 minute
    * count remaining elements, reject request here if count is greater than 3
    * insert current time into sorted set and accept the request

* how much memory do we need to store this user data for sliding window solution?
  * Assume user_id takes 8 bytes, epoch time takes 4 bytes
  * suppose we need a rate limiting of 500 requests / hour
  * 20 bytes of overhead for hash table
  * 20 bytes overhead for sorted set
  * At max, we need 12KB for one user's data
    * 8 + (4 + 20ss) * 500 + 20ht = 12 KB
    * here we've reserved 20 bytes overhead per element in a sorted set
    * need two pointers to maintain order, prev, next
      * each ptr is 8 bytes on a 64 bit machine
      * added an extra word for other overhead
    * 1 million users * 12KB = 12GB
  * sliding window takes a lot more memory compared to fixed window
  * this would be a scalability issue, can we combine them?

## Sliding Window with Counters
* track request counts for each user using multiple fixed time windows
* ex: 1/60th the size of our rate limit's time window
* ex: for an hourly rate limit, we keep a count for each minute
  * calculate sum of all counters in past hour when we receive a new request to calculate throttling limit
  * reduces memory footprint
* when the sum of the counters for each minute in last hour > 500, throttle the request
* in addition, she can only send 10 requests per minute
  * this is reasonable and practical, as real users would not send frequent requests
* store counters in a Redis Hash
  * very efficient for < 100 keys
  * each request increments a counter in the hash, hash is set to expire in one hour
  * normalize each time to a minute
    * timestamp -> minute number
* how much mem for sliding window with counters
  * user_id is 8 bytes, epoch time is 4 bytes, counter is 2 bytes
  * 500 requests / hour
  * 20 bytes overhead for hash-table, 20 bytes for redis hash
  * 8 + (4 + 2+ 20 (Redis Hash overhead)) * 60 + 20 (hash-table overhead) = 1.6KB
  * for 1 million users
    * 1.6KB * 1m = 1.6GB
  * 86% less than naive sliding window algorithm

## Data Sharding and Caching
* shard based on user_id to distribute user's data
* use consistent hashing for fault tolerance and replication
* if we want different throttlign limits for different apis, we can shard per user per API
* Ex: URL Shortener
  * different rate limiter for create_url and delete_url per user / ip
* if apis are partitioned
  * we could have a separate smaller rate limiter for each api shard as well
  * rate limit each partition to allow a user to create not more than 3 short urls per minute, 100 per hour
* We can cache recent active users
* application servers hit cache first before backend
* rate limiter benefits from write back cache
  * update counters and timestamps in cache only
  * write to permanant storage can be done at fixed intervals
  * ensure minimum latency added by rate limiter
  * reads can always hit cache first
  * LRU

## Limit by IP or User
* Ip
  * limit based on ip
  * not optimal for differentiating bad and good actors
  * better than no rate limits
  * bad for stuff like internet cafe or phone users on same router
  * one bad user can throttle other people
  * caching IP-based limits can cause issue
    * LOTS of IPv6 addresses
* User
  * Rate limits happen on APIs after user authentication
  * once authenticated, user is provided with token, which will be passed with each request
  * ensures we rate limit against particular api with valid auth token
  * what if we have to rate limit on login API?
    * hacker can cause a DOS attack against a user by entering wrong credentials up to the limit
    * actual user cannot log in then
* Hybrid
  * can do both
  * more mem
